{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnL2Q01p6YCB"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(doc):\n",
        "  tokens = word_tokenize(doc.lower())\n",
        "  return [stemmer.stem(token) for token in tokens if token.isalnum()]\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(subset = \"train\", categories = [\"sci.space\", \"comp.graphics\"], remove = (\"headers\", \"footers\", \"quotes\"))\n",
        "corpus = dataset.data[:10]"
      ],
      "metadata": {
        "id": "zrC30X0H-cux"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k1 = 1.25 # Term frequency Scaling\n",
        "b = 0.80 # Document Length Scaling\n",
        "\n",
        "preprocessed_corpus = [preprocess(doc) for doc in corpus]\n",
        "document_lengths = [len(doc) for doc in preprocessed_corpus]\n",
        "avgdl = sum(document_lengths)/len(document_lengths)\n",
        "\n",
        "term_frequencies = [Counter(doc) for doc in preprocessed_corpus]"
      ],
      "metadata": {
        "id": "_67GYIeDCW0E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_document_frequencies(corpus):\n",
        "  df = Counter()\n",
        "  for doc in corpus:\n",
        "    unique_terms = set(doc)\n",
        "    for term in unique_terms:\n",
        "      df[term] += 1\n",
        "  return df"
      ],
      "metadata": {
        "id": "3q4kUCu4C8co"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_frequencies = compute_document_frequencies(preprocessed_corpus)\n",
        "N = len(corpus)\n",
        "\n",
        "def compute_idf(term, df, N):\n",
        "  return math.log((N - df[term] + 0.5)/(df[term] + 0.5) + 1)\n",
        "\n",
        "idf = {term : compute_idf(term, document_frequencies, N) for term in document_frequencies}\n",
        "\n",
        "def compute_bm25_score(query, doc_index):\n",
        "  query_terms = preprocess(query)\n",
        "  score = 0\n",
        "  for term in query_terms:\n",
        "    if term not in idf:\n",
        "      continue\n",
        "\n",
        "    tf = term_frequencies[doc_index][term]\n",
        "    dl = document_lengths[doc_index]\n",
        "\n",
        "    numerator = tf * (k1 + 1)\n",
        "    denominator = tf + k1 * (1 - b + b * dl/avgdl)\n",
        "    score += idf[term] * (numerator/denominator)\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "O99BjUR6Kds8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_documents(query):\n",
        "  scores = []\n",
        "  for doc_index in range (len(corpus)):\n",
        "    score = compute_bm25_score(query, doc_index)\n",
        "    scores.append((doc_index, corpus[doc_index]))\n",
        "\n",
        "  return sorted(scores, key = lambda x: x[0], reverse = True)\n",
        "\n",
        "query = \"space technology\"\n",
        "ranked_results = rank_documents(query)\n",
        "\n",
        "print(f\"Query: {query}'\\n\")\n",
        "print(\"Ranked results: \")\n",
        "for score, doc in ranked_results:\n",
        "  print(f\"Score: {score:.4f} | Document: {doc[:100]}...\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyf2V0ulL0mv",
        "outputId": "84e7889a-cbe5-45d8-e18f-4280b0f5aea8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: space technology'\n",
            "\n",
            "Ranked results: \n",
            "Score: 9.0000 | Document: \n",
            "\n",
            "THANKS!  It did work, and it is just what I needed thanks......\n",
            "Score: 8.0000 | Document: \n",
            "I don't know about that...I've used Photoshop 2.5 on both a 486dx-50 and a Quadra\n",
            "950...I'd say the...\n",
            "Score: 7.0000 | Document: ====\n",
            "If that were true, I'd go for it.. I have a few friends who we could pool our\n",
            "resources and do ...\n",
            "Score: 6.0000 | Document: \n",
            "Hi,\n",
            "It might be nice to know, what's possible on different hard ware platforms.\n",
            "But usually the har...\n",
            "Score: 5.0000 | Document: I'm a mac user who wants to use some of the rayshade models I've built\n",
            "using macrayshade (rayshade-M...\n",
            "Score: 4.0000 | Document: [Lots of stuff about how the commerical moonbase=fantasyland]\n",
            "\n",
            "Then what do you believe will finally...\n",
            "Score: 3.0000 | Document: I read it refered to as the \"parabolic cross-section\" rule;\n",
            "the idea was that if you plot the area o...\n",
            "Score: 2.0000 | Document: I am currently using POVRay on Mac and was wondering if anyone in netland\n",
            "knows of public domain ant...\n",
            "Score: 1.0000 | Document: \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "It still applies, except the astronomy these days is Very Long Baseline\n",
            "Radio Astronomy couple...\n",
            "Score: 0.0000 | Document: \n",
            "I usually use \"Algorithms for graphics and image processing\" by\n",
            "Theodosios Pavlidis, but other peop...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import nltk\n",
        "from collections import Counter\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess(doc):\n",
        "    tokens = word_tokenize(doc.lower())\n",
        "    return [stemmer.stem(token) for token in tokens if token.isalnum()]\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "dataset = fetch_20newsgroups(subset=\"train\", categories=[\"sci.space\", \"comp.graphics\"], remove=(\"headers\", \"footers\", \"quotes\"))\n",
        "corpus = dataset.data[:10]\n",
        "\n",
        "k1 = 1.25\n",
        "b = 0.80\n",
        "\n",
        "preprocessed_corpus = [preprocess(doc) for doc in corpus]\n",
        "document_lengths = [len(doc) for doc in preprocessed_corpus]\n",
        "avgdl = sum(document_lengths) / len(document_lengths)\n",
        "\n",
        "term_frequencies = [Counter(doc) for doc in preprocessed_corpus]\n",
        "\n",
        "def compute_document_frequencies(corpus):\n",
        "    df = Counter()\n",
        "    for doc in corpus:\n",
        "        unique_terms = set(doc)\n",
        "        for term in unique_terms:\n",
        "            df[term] += 1\n",
        "    return df\n",
        "\n",
        "document_frequencies = compute_document_frequencies(preprocessed_corpus)\n",
        "N = len(corpus)\n",
        "\n",
        "def compute_idf(term, df, N):\n",
        "    return math.log((N - df[term] + 0.5) / (df[term] + 0.5) + 1)\n",
        "\n",
        "idf = {term: compute_idf(term, document_frequencies, N) for term in document_frequencies}\n",
        "\n",
        "def compute_bm25_score(query, doc_index):\n",
        "    query_terms = preprocess(query)\n",
        "    score = 0\n",
        "    for term in query_terms:\n",
        "        if term not in idf:\n",
        "            continue\n",
        "        tf = term_frequencies[doc_index][term]\n",
        "        dl = document_lengths[doc_index]\n",
        "        numerator = tf * (k1 + 1)\n",
        "        denominator = tf + k1 * (1 - b + b * dl / avgdl)\n",
        "        score += idf[term] * (numerator / denominator)\n",
        "    return score\n",
        "\n",
        "def rank_documents(query):\n",
        "    scores = []\n",
        "    for doc_index in range(len(corpus)):\n",
        "        score = compute_bm25_score(query, doc_index)\n",
        "        scores.append((score, corpus[doc_index]))\n",
        "    return sorted(scores, key=lambda x: x[0], reverse=True)\n",
        "\n",
        "query = \"space technology\"\n",
        "ranked_results = rank_documents(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(\"Ranked results: \")\n",
        "for score, doc in ranked_results:\n",
        "    print(f\"Score: {score:.4f} | Document: {doc[:100]}...\")\n"
      ],
      "metadata": {
        "id": "_IFakcunQLMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}